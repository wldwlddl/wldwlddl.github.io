#### 목표
- 데이터 전처리 필요성

#### 결과
- 데이터 전처리- 데이터 분석을 위해 반드시 필요한 작업. 이를 하지 않으면 정상적인 분석이 나오지 않을 수 있다. 

- 결측치-데이터에 값이 없는 것 혹은 관측되지 않은 것. Null이라 표현한다. 이를 포함하고 분석을 진행하면 오류가 나거나 이상한 분석 결과가 나와 제거하거나 대체해야 한다. 대체할 경우 처리 방법은 다음과 같다.
1. 평균이나 중앙치로 대체 혹은 mode값으로 대체
2. 간단한 예측 모델로 대체

- 먼저 1번의 경우 데이터가 숫자와 같은 수치형일 경우 평균 혹은 중앙치로 대체하고 범주형(수치로 측정 불가능한 자료 e.g. 성별, 지역, 혈액형 등)일 경우 모드값(가장 많이 관측되는 수)으로 대체된다. 
_추가로 어떤 데이터인지, 어디서 온 데이터인지 알아두면 데이터 전처리 하는 데 유용하다. 
p.s. NA와 Null의 차이점
NA: Not Available
Null: empty object
NaN: not a Number
```
#결측치 부분 메꾸기(viewCount의 평균값으로 바꿈)
test['X'] = test['X'].fillna(test.X.mean())
```

- 이상치- 데이터셋에서 다른 값들보다 크게 다른 값. 이 또한 분석을 진행하면 이상한 분석 결과가 나올 수 있기 때문에 이 또한 다음과 같은 처리 과정을 거친다. 
1. 표준점수로 변환 후 -3이하 및 +3 제거 
2. IQR 방식
3. Binning 처리

- 1번의 방식은 평균이 0, 표준편차가 1인 분포로 변환한 뒤 값이 -3 혹은 +3이상일 때 처리된다.
- 2번의 방식은 데이터를 4등분 한 다음 그 중 25%와 75%지점의 값의 차이를 극단치로 처리하는 방식이다.
- 3번은 구간화라고도 하는데 수치형 자료를 범주형으로 바꾸는 작업이다.

- 데이터 분포 변환-말 그대로 데이터의 열(변수)의 분포를 함수 등을 이용해 변환. 데이터를 학습 모델에 넣을 때, 대부분의 모델들은 데이터가 특정 분포를 따를 거라고 가정한다. 따라서 보통 데이터를 Log나 Exp(e^)등의 함수를 이용해 데이터 분포를 변환하게 한다. 
```
#log함수 적용
#데이터 'X'의 열에만 반영
df['X_log'] = preprocessing.scale(np.log(df['X']+1)) 
```

- 데이터 단위 변환- 데이터의 단위를 일정하게 맞추는 작업. 데이터의 단위가 다르면 거리를 기반으로 하는 모델을 사용했을 때 결과가 이상하게 나올 수 있으므로, 단위를 일정하게 맞추는 스케일링이라는 작업을 해야 한다. 많은 통계 분석 방법이 데이터가 종 모양의 분포를 이룬다는 정규성 가정을 기반한다고 하므로 최대한 정규분포로 변환해야 한다.

1. scaling: 평균이 0, 분산이 1인 분포로 변환
2. minmax scaling: 특정 범위로 모든 데이터 변환
3. Box-Cox: 여러 k값 중 가장 작은 sse() 선택
4. robust_scale: 중앙값, IQR사용

```
#위의 scaling 적용
df['X_scale'] = preprocessing.scale(df['X']) df['X_minmax_scale'] = preprocessing.MinMaxScaler(df['X'] df['X_boxcox'] = preprocessing.scale(boxcox(df['X']+1)[0]) df['X_robust_scale'] = preprocessing.robust_scale(df['X'])
#데이터 'X'에만 scaling 적용
```


p.s 데이터의 열과 변수는 종종 같은 이름으로 쓰임