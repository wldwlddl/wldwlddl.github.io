#### 목표
- gan이 뭔지 알기
- 실습을 위한 코드조사

#### 공부 결과

###### gan
-  Generative Adversarial Networks(적대적 생성 신경망)의 약자로 생성 AI 모델 중 하나이다. 서로 다른 두 개의 네트워크를 적대적으로 학습시키며 실제 데이터와 비슷한 데이터를 생성해내는 모델이다.
- 이때 gan은 Genaerator(생성기), discriminator(판별기)라는 서로 다른 2개의 네트워크로 이루어져 있다. 생성기는 진짜 데이터셋에 가까운 가짜 데이터를 생성하고 판별기는 주어지는 표본이 가짜인지 진짜인지를 결정하는 방식이다. gan의 목적은 실제 데이터의 분포에 가까운 데이터를 생성하는 것이다. 이러한 특성으로 gan은 레이블이 따로 없는 비지도 학습에 속한다. 

###### 코드
- 아래는 인터넷에서 가져온 예시 gan 모델 코드이다. 나는 이미지 데이터셋을 사용했다. 
```
!pip install imageio
#  imageio: 이미지와 동영상 파일을 읽고 쓰는 데 사용되는 파이썬 라이브러리
import torch
import torch.nn as nn # 파이토치의 신경망 모듈을 nn이라는 약어로 import하겠단 명령어
import torch.optim as optim # 최적화 알고리즘을 구현하는 패키지
from torchvision import datasets, transforms
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import os
import numpy as np
```

```
# Function to set the seed for reproducibility
import random
def set_seed(seed_value=42):
    """Set seed for reproducibility."""
    np.random.seed(seed_value)
    torch.manual_seed(seed_value)
    torch.cuda.manual_seed(seed_value)
    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.
    random.seed(seed_value)
    os.environ['PYTHONHASHSEED'] = str(seed_value)
    # The below two lines are for deterministic algorithm behavior in CUDA
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Set the seed
set_seed()
```
- 이 과정은 머신러닝이나 딥러닝에서 재현성(동일한 데이터와 코드로 동일한 결과를 얻는 것)을 보장하기 위해 시드(특정한 시작 숫자. 이를 이용해서 컴퓨터는 정해진 알고리즘에 따라 난수처럼 보이는 수열을 생성함)를 설정하는 함수이다.  위에서 Numpy, Pytorch의 CPU의 랜덤 생성기 시드, 내장 모듈 random의 랜덤 넘버 생성기, 파이썬의 해시 시드를 설정하였다. 
```
dataloader = torch.utils.data.DataLoader(
    datasets.MNIST('./data/mnist', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.Resize(28),
                       transforms.ToTensor(),
                       transforms.Normalize([0.5], [0.5])  # Normalize to range [-1, 1]
                   ])),
    batch_size=64, shuffle=True)

```
- mnist라는 파이토치에서 제공하는 데이터셋을 사용하였다. compose는 여러 변환을 연속적으로 적용하고 Resize는 이미지를 28 * 28사이즈로 조정하고 ToTensor는 이미지를 파이토치 텐서로 변환한다. 또한 Normalize는 이미지의 픽셀 값을 정규화하여 [-1, 1] 범위로 변환한다. 아래는 전체 중 64개의 샘플을 무작위로 섞어서 불러온다는 뜻이다.
```
import torch
import torch.nn as nn

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(28*28, 1024),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()  # Sigmoid activation to output probabilities
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        return self.model(img_flat)
```
-  판별자를 정의하는 코드이다. 입력된 이미지가 실제 데이터인지 생성된 데이터인지를 구분하는 역할을 한다. 먼저 클래스를 만들고 입력 이미지를 평탄화하고 leaky ReLU 활성화 ㅎ마수로 음수 영역에 작은 기울기를 주고 과적합을 방지하고 노드를 줄여 최종적으로 1개의 출력으로 줄이는 선형 레이어를 만든 후 출력값을 [0,1] 범위로 변환하여 확률로 계산할 수 있게 한다. forward부분은 입력 이미지를 평탄화여 모델에서 출력값을 얻도록 하는 코드이다. 

```
# Loss function
criterion = nn.BCELoss()

# Number of epochs
num_epochs = 100

# For visualizing the progress
fixed_noise = torch.randn(64, 100, device=device)

os.makedirs('./images', exist_ok=True)
os.makedirs('./results', exist_ok=True)

# Training loop
for epoch in range(num_epochs):
    for i, (real_images, _) in enumerate(dataloader):
        if epoch == 0 and i == 0:
            sample_real_images = real_images # to keep batch_size

        batch_size = real_images.size(0)

        # Real labels are 1, fake labels are 0
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Train Discriminator with real images
        discriminator.zero_grad()
        outputs = discriminator(real_images.to(device))
        d_loss_real = criterion(outputs, real_labels)
        real_score = outputs

        # Train Discriminator with fake images
        noise = torch.randn(batch_size, 100, device=device)
        fake_images = generator(noise)
        outputs = discriminator(fake_images.detach())
        d_loss_fake = criterion(outputs, fake_labels)
        fake_score = outputs

        # Backprop and optimize for discriminator
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        generator.zero_grad()
        outputs = discriminator(fake_images)
        g_loss = criterion(outputs, real_labels)

        # Backprop and optimize for generator
        g_loss.backward()
        optimizer_G.step()

        if (i+1) % 200 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, D(x): {real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}')

    # Save real images once for comparison
    if epoch == 0:
        save_image(sample_real_images, './images/real_images.png')

    # Save sampled images every epoch
    fake_images = generator(fixed_noise)
    save_image(fake_images, f'./images/fake_images_epoch_{epoch+1:04d}.png')

    # Save discriminator results for each image in the grid
    discriminator_results = discriminator(fake_images).cpu().detach().numpy().reshape(8, 8)
    np.save(f'./results/discriminator_outputs_epoch_{epoch+1:04d}.npy', discriminator_results)

print('Training finished.')
```
- 이는 간단히 모델을 학습시킬 총 에포크 수를 정하고 진짜 이미지를 사용해 판별자를 학습한 후 가짜 이미지를 다시 학습하고 생성자는 판별자를 속이기 위해 진짜처럼 보이는 이미지를 생성하도록 학습된다. 

- 이후 학습된 생성자 이미지를 생성하고 시각화하면 얼마나 실제 이미지와 비슷한지 확인할 수 있다. 
- 이 외에 타 코드를 이용해 계란을 학습하고 나온 결과물이다.
![[egg_.png]]

#### 후기
- 코드를 실행시켜보는데 정말 원하는 대로 결과가 나오지 않아 답답하고 어디를 어떻게 고쳐야 하는지 감이 잘 오지 않았다. 만들어본 생성 이미지는 꿈에 나올까 무서울 수준이고 계란 이미지를 사용했는데 어디를 봐야 계란이 나오는지 모르겠다. 절망스러웠지만 어디를 고쳐야하는지부터 알아보기로 했다.